# -*- coding: utf-8 -*-
"""DistilBERT500.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vfPlTQlUr5TKTEqp5cQCnsfszdmFxSaD

# **DistilBERT**

# Install necessary libraries
"""

!pip install transformers datasets scikit-learn torchinfo matplotlib seaborn

"""Import required libraries"""

import torch
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
from sklearn.model_selection import train_test_split
from torchinfo import summary
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""upload the dataset"""

#  Upload the dataset
from google.colab import files
uploaded = files.upload()

"""# Dataset： Xstest

## load and prepare the dataset Xstest
"""

#  Load the dataset
train_df = pd.read_csv('xstest_train_clean.csv')
test_df = pd.read_csv('xstest_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=16)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=16)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_xstest_full")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_xstest_full")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["You did an amazing job on that project! Keep up the great work!", "I'm really impressed with how thoughtful and kind you are.", "You're so useless, I don’t even know why you bother.", "No one likes you, and you should just stop talking.", "Honestly, it's kind of pathetic that you still believe that.", "You really think you're better than everyone else, don't you?"]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## Hyperparameter Tuning"""

from transformers import Trainer, TrainingArguments
import matplotlib.pyplot as plt

# List of learning rates to try
learning_rates = [5e-5, 3e-5, 2e-5]

# Dictionary to store evaluation results for each learning rate
results_dict = {}

# Reduce the dataset size for faster experimentation
small_train_dataset = train_dataset.select(range(200))  # Select the first 200 samples for training
small_val_dataset = val_dataset.select(range(40))       # Select the first 40 samples for validation
small_test_dataset = test_dataset.select(range(40))     # Select the first 40 samples for testing

for lr in learning_rates:
    print(f"Training with learning rate: {lr}")

    # Adjust the learning rate and number of epochs for quicker training
    training_args = TrainingArguments(
        output_dir='./results',
        evaluation_strategy="epoch",
        save_strategy="epoch",  # Set save strategy to match evaluation strategy
        logging_strategy="steps",
        logging_steps=10,
        learning_rate=lr,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=3,
        weight_decay=0.01,
        logging_dir='./logs',
        load_best_model_at_end=True,  # Still keep this to load the best model
        metric_for_best_model="eval_loss"  # Define the metric to monitor
    )

    # Set up the trainer without early stopping
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=small_train_dataset,
        eval_dataset=small_val_dataset,
        compute_metrics=compute_metrics
    )

    # Train the model
    trainer.train()

    # Evaluate the model
    eval_results = trainer.evaluate(small_test_dataset)

    # Save the evaluation results in the dictionary
    results_dict[lr] = eval_results
    print(f"Results with learning rate {lr}: {eval_results}")

# Plot learning rates vs accuracy
accuracies = [results_dict[lr]['eval_accuracy'] for lr in learning_rates]
plt.plot(learning_rates, accuracies, marker='o')
plt.xlabel('Learning Rate')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Learning Rate')
plt.xscale('log')  # Use log scale for the learning rate
plt.show()

"""## pre-trained model test result without training for comparison"""

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset: HatespeachDetection 500

## load and prepare the dataset HateSpeachDetection 500
"""

# Load the dataset
train_df = pd.read_csv('HateSpeechDetection_small500_train_Clean.csv')
test_df = pd.read_csv('HateSpeechDetection_small500_test_Clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=40)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=40)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=40)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_HateSpeachDetection_500")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_HateSpeachDetection_500")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["You did an amazing job on that project! Keep up the great work!", "I'm really impressed with how thoughtful and kind you are.", "You're so useless, I don’t even know why you bother.", "No one likes you, and you should just stop talking.", "Honestly, it's kind of pathetic that you still believe that.", "You really think you're better than everyone else, don't you?"]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## pre-trained model test result without training for comparison"""

test_df = pd.read_csv('HateSpeechDetection_simple_test_Clean.csv')

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset: Toxicchat 500

## load the dataset toxicchat 500
"""

#  Load the dataset
train_df = pd.read_csv('df_tocxicchat1_small500_train_clean.csv')
test_df = pd.read_csv('df_tocxicchat1_small500_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=90)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=90)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=90)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_toxicchat_500")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_toxicchat_500")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["You did an amazing job on that project! Keep up the great work!", "I'm really impressed with how thoughtful and kind you are.", "You're so useless, I don’t even know why you bother.", "No one likes you, and you should just stop talking.", "Honestly, it's kind of pathetic that you still believe that.", "You really think you're better than everyone else, don't you?"]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## pre-trained model test result without training for comparison"""

test_df = pd.read_csv('df_tocxicchat1_simple_test_Clean.csv')

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset: Toxicgen 500

## load and prepare the dataset Toxicgen 500
"""

# Load the dataset
train_df = pd.read_csv('df_toxicgen1_small500_train_clean.csv')
test_df = pd.read_csv('df_toxicgen1_small500_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=40)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=40)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=40)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_Toxicgen_500")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_Toxicgen_500")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["You did an amazing job on that project! Keep up the great work!", "I'm really impressed with how thoughtful and kind you are.", "You're so useless, I don’t even know why you bother.", "No one likes you, and you should just stop talking.", "Honestly, it's kind of pathetic that you still believe that.", "You really think you're better than everyone else, don't you?"]

inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## pre-trained model test result without training for comparison"""

test_df = pd.read_csv('df_toxicgen1_simple_test_Clean.csv')

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset：Ethics 500

## load and prepare the dataset Ethics 500
"""

# Load the dataset
train_df = pd.read_csv('ds_ethics_commonsense_small500_train_clean.csv')
test_df = pd.read_csv('ds_ethics_commonsense_small500_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=400)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=400)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=400)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_Ethics_500")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_Ethics_500")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["You did an amazing job on that project! Keep up the great work!", "I'm really impressed with how thoughtful and kind you are.", "You're so useless, I don’t even know why you bother.", "No one likes you, and you should just stop talking.", "Honestly, it's kind of pathetic that you still believe that.", "You really think you're better than everyone else, don't you?"]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## pre-trained model test result without training for comparison"""

test_df = pd.read_csv('ds_ethics_commonsense_simple_test_Clean.csv')

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""# Dataset：superset 500

## load and prepare the dataset Superset 500
"""

# Load the dataset
train_df = pd.read_csv('superset_train_small500_train.csv')
test_df = pd.read_csv('superset_train_small500_test.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

"""Split the data into training, validation, and test sets"""

X = train_df['prompt']
y = train_df['label']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""Tokenize the train, validation, and test data"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=100)
val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=100)
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=100)

"""Create PyTorch datasets"""

train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'],
                                   'attention_mask': train_encodings['attention_mask'],
                                   'labels': y_train.tolist()})
val_dataset = Dataset.from_dict({'input_ids': val_encodings['input_ids'],
                                 'attention_mask': val_encodings['attention_mask'],
                                 'labels': y_val.tolist()})
test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'],
                                  'attention_mask': test_encodings['attention_mask'],
                                  'labels': test_df['label'].tolist()})

"""## Load pretrained DistilBERT model"""

model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

"""Freeze 50% of the top layers for fine-tuning"""

for param in model.distilbert.transformer.layer[:3]:  # Freezing the first 3 layers out of 6 (50%)
    for p in param.parameters():
        p.requires_grad = False

"""print the model summary"""

import torch
from torchinfo import summary

# Ensure the model is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Create a dummy input with the correct tensor type (LongTensor)
dummy_input = torch.randint(0, tokenizer.vocab_size, (1, 40), dtype=torch.long).to(device)

# Print the model summary
summary(model, input_data=dummy_input)

"""set training arguments"""

# Set training arguments
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",  # Enable logging for each epoch to track training loss
    logging_steps=10,  # Log every 10 steps (or adjust as needed)
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',
)

"""Define metrics for evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

"""## Model training"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

"""## Save the model"""

# Save the trained model
model.save_pretrained("DistilBERT_Superset_500")

"""Reload the model"""

# Load the saved model (optional step)
loaded_model = DistilBertForSequenceClassification.from_pretrained("DistilBERT_Superset_500")

"""## Evaluate the model on the test set and generate results"""

# Evaluate the model on the test set
results = trainer.evaluate(test_dataset)

# Print evaluation results
print(f"Test set results: {results}")

"""Generate confusion matrix and classification report"""

from sklearn.metrics import classification_report, confusion_matrix

y_true = test_df['label']
y_pred = torch.from_numpy(trainer.predict(test_dataset).predictions).argmax(dim=1)

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))

"""## Inference with sample texts"""

# Inference with sample texts
texts = ["You did an amazing job on that project! Keep up the great work!", "I'm really impressed with how thoughtful and kind you are.", "You're so useless, I don’t even know why you bother.", "No one likes you, and you should just stop talking.", "Honestly, it's kind of pathetic that you still believe that.", "You really think you're better than everyone else, don't you?"]
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Perform inference
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Print predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} | Predicted label: {label}")

"""## pre-trained model test result without training for comparison"""

test_df = pd.read_csv('superset_train_small500_test.csv')

# Load the pretrained model
pretrained_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Ensure the model is in evaluation mode
pretrained_model.eval()

# Tokenize the test data
test_encodings = tokenizer(test_df['prompt'].tolist(), truncation=True, padding=True, max_length=16)

# Create the test dataset
test_dataset = Dataset.from_dict({
    'input_ids': test_encodings['input_ids'],
    'attention_mask': test_encodings['attention_mask'],
    'labels': test_df['label'].tolist()
})

# Perform inference on the test dataset using the pretrained model
predictions = []
with torch.no_grad():
    for i in range(len(test_dataset)):
        inputs = {
            'input_ids': torch.tensor(test_encodings['input_ids'][i]).unsqueeze(0),
            'attention_mask': torch.tensor(test_encodings['attention_mask'][i]).unsqueeze(0)
        }
        outputs = pretrained_model(**inputs)
        pred = torch.argmax(outputs.logits, dim=-1)
        predictions.append(pred.item())

# Generate the confusion matrix and classification report
y_true = test_df['label']
y_pred = predictions

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Plot the Confusion Matrix as a heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Non-Toxic', 'Toxic']))