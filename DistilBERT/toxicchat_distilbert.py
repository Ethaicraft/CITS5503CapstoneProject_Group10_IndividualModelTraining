# -*- coding: utf-8 -*-
"""ToxicChat_DistilBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/127S624fDDzhRAtMXk-NONiNUd-bVsqmR

# **DistilBERT**

Dataset: Toxic Chat

# 1. Install and Import libraries
"""

# Install necessary libraries
!pip install transformers datasets scikit-learn

# Import necessary libraries
import numpy as np
import pandas as pd
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

"""# 2. Load and prepare the Dataset"""

#  Upload the dataset
from google.colab import files
uploaded = files.upload()

#  Load the dataset
train_df = pd.read_csv('df_tocxicchat1_train_clean.csv')
test_df = pd.read_csv('df_tocxicchat1_test_clean.csv')

# Display basic data information
print(train_df.head())
print(test_df.head())

# Convert the Pandas DataFrame to Hugging Face Dataset format
train_dataset = Dataset.from_pandas(train_df)
test_dataset = Dataset.from_pandas(test_df)

"""tokenize the text"""

# Preprocess the data (tokenize text)
tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add padding token explicitly

def preprocess_function(examples):
    return tokenizer(examples['prompt'], padding="max_length", truncation=True, max_length=128)

# Apply preprocessing to both train and test datasets
tokenized_train = train_dataset.map(preprocess_function, batched=True)
tokenized_test = test_dataset.map(preprocess_function, batched=True)

# Rename the 'label' column to 'labels' for compatibility with Trainer
tokenized_train = tokenized_train.rename_column("label", "labels")
tokenized_test = tokenized_test.rename_column("label", "labels")

"""# 3. DistilBERT model building

Initialize the DistilBERT model
"""

# Initialize the DistilBERT
model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)

"""Define the metrics function"""

# Define custom metrics function (including loss)
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import numpy as np

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)

    # Compute standard metrics
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=1)
    acc = accuracy_score(labels, preds)

    # Compute confusion matrix
    cm = confusion_matrix(labels, preds)

    # Extract confusion matrix components
    tn, fp, fn, tp = cm.ravel()

    # Return metrics including confusion matrix elements
    return {
        'accuracy': acc,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'confusion_matrix_00': tn,  # True negatives
        'confusion_matrix_01': fp,  # False positives
        'confusion_matrix_10': fn,  # False negatives
        'confusion_matrix_11': tp   # True positives
    }

"""Set the training arguments"""

# Set training arguments
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_strategy="epoch",      # Enable logging per epoch
    logging_steps=10,          # Optionally log every 10 steps
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir='./logs',        # Directory to save logs
)

"""Initialize trainer"""

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_test,
    compute_metrics=compute_metrics
)

"""# 4. Model performance without training for comparison"""

# Evaluate model without training (for comparison)
predictions_before_training = trainer.predict(tokenized_test)

# Extract true and predicted labels before training
true_labels_pre = predictions_before_training.label_ids
predicted_labels_pre = predictions_before_training.predictions.argmax(-1)

# Compute and plot confusion matrix for pre-training evaluation
cm_pre = confusion_matrix(true_labels_pre, predicted_labels_pre)
plt.figure(figsize=(5, 5))
sns.heatmap(cm_pre, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')
plt.title('Confusion Matrix (Pre-training)')
plt.show()

# Print baseline results
print("Before training predictions:\n", predictions_before_training.metrics)

# Print baseline results
print("Before training predictions:\n", predictions_before_training.metrics)

"""# 5. Model Training"""

# Step 11: Train the model
trainer.train()

"""# 6. Model Evaluation"""

# Evaluate the model
results = trainer.evaluate()

# Extract confusion matrix components
cm = np.array([[results['eval_confusion_matrix_00'], results['eval_confusion_matrix_01']],
               [results['eval_confusion_matrix_10'], results['eval_confusion_matrix_11']]])

# Visualize the confusion matrix
plt.figure(figsize=(5, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')
plt.title('Confusion Matrix (Post-training)')
plt.show()

# Print final evaluation results
print("Evaluation results:\n", results)

"""# 7. Model Inference"""

# Import torch
import torch

# Perform Inference (Prediction)
texts = ["Here is a good review, you are so nice.", "You are a piece of sh*t."]

# Tokenize the input text for inference
inference_encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')

# Ensure the model is in evaluation mode
model.eval()

# Make predictions
with torch.no_grad():
    outputs = model(**inference_encodings)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)

# Decode the predictions
labels = ['Non-Toxic', 'Toxic']
predicted_labels = [labels[pred] for pred in predictions]

# Display the inference results
for i, text in enumerate(texts):
    print(f"Text: {text}")
    print(f"Predicted Label: {predicted_labels[i]}\n")